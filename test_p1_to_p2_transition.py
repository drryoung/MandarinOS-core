#!/usr/bin/env python3
"""
P1‚ÜíP2 Transition Test Suite

Validates signal flow from P1 diagnostic completion through P2 engine selection.
Tests that:
1. P1 signals aggregate and flow to P2 readiness determination
2. P2 engine selection is pattern-based (not score-threshold-based)
3. No data loss across phase boundary
4. Confidence levels map correctly to engine readiness
5. Signal patterns determine engine routing (intent-matching, not averaging)

Compliance Targets:
- ¬ß 3.1 Turn option invariant (P1 gold options carry metadata)
- ¬ß 3.2 Frame-slot invariant (slot patterns flow to P2 engine routing)
- ¬ß 3.4 Diagnostic confidence (no arbitrary thresholds, pattern-based routing)
"""

import json
import sys
import io

# UTF-8 wrapper for Windows console
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# Load diagnostic and engine configs
with open('diagnostic_p1.json', 'r', encoding='utf-8') as f:
    diagnostic_p1 = json.load(f)

with open('diagnostic_p2.json', 'r', encoding='utf-8') as f:
    diagnostic_p2 = json.load(f)

with open('p1_engines.json', 'r', encoding='utf-8') as f:
    p1_engines = json.load(f)

with open('p2_engines.json', 'r', encoding='utf-8') as f:
    p2_engines = json.load(f)

with open('srs_config.json', 'r', encoding='utf-8') as f:
    srs_config = json.load(f)

# Test data structure
results = {
    "passed": [],
    "failed": [],
    "warnings": []
}

# ==================== TEST 1: P1 Signal Extraction & Aggregation ====================
print("\n" + "="*70)
print("P1‚ÜíP2 TRANSITION TEST SUITE - Signal Flow Validation")
print("="*70)

print("\n1Ô∏è‚É£  TESTING P1 SIGNAL EXTRACTION & AGGREGATION...")

# Simulate three P1 session outcomes: high, medium, low confidence
test_scenarios = {
    "high_confidence": {
        "description": "All gold options selected (6/6)",
        "selections": {
            "p1_greeting": "a",      # gold
            "p1_name": "a",          # gold
            "p1_nationality": "a",   # gold
            "p1_location": "a",      # gold
            "p1_yesno": "yes",       # gold
            "p1_opinion": "a",       # gold
        },
        "expected_confidence": "high",
        "expected_signals": ["greeting_reciprocal", "name_introduce", "nationality_identify", 
                            "location_state", "affirmative_response", "opinion_express"]
    },
    "medium_confidence": {
        "description": "3 gold, 3 distractor (3/6)",
        "selections": {
            "p1_greeting": "a",      # gold
            "p1_name": "a",          # gold
            "p1_nationality": "b",   # distractor
            "p1_location": "b",      # distractor
            "p1_yesno": "yes",       # gold
            "p1_opinion": "b",       # distractor
        },
        "expected_confidence": "medium",  # exactly at >= 3 threshold
        "expected_signals": ["greeting_reciprocal", "name_introduce", 
                            "affirmative_response"]  # only gold signals
    },
    "low_confidence": {
        "description": "2 gold, 4 distractor (2/6)",
        "selections": {
            "p1_greeting": "b",      # distractor
            "p1_name": "a",          # gold
            "p1_nationality": "b",   # distractor
            "p1_location": "b",      # distractor
            "p1_yesno": "no",        # ambiguous
            "p1_opinion": "d",       # distractor
        },
        "expected_confidence": "low",
        "expected_signals": ["name_introduce"]  # sparse signals
    }
}

for scenario_name, scenario_data in test_scenarios.items():
    print(f"\n  Scenario: {scenario_data['description']}")
    
    # Aggregate signals for this scenario
    signals_collected = []
    gold_count = 0
    task_count = 0
    
    for task_id, selection in scenario_data["selections"].items():
        task = next((t for t in diagnostic_p1.get("tasks", []) if t.get("id") == task_id), None)
        if not task:
            results["failed"].append(f"‚ùå Task {task_id} not found in P1")
            continue
        
        task_count += 1
        
        # Find the selected option
        selected_option = None
        if task_id == "p1_yesno" and selection in ["yes", "no"]:
            # Special case for yes/no
            selected_option = next((o for o in task.get("choices", []) if o.get("id") == selection), None)
        else:
            selected_option = next((o for o in task.get("choices", []) if o.get("id") == selection), None)
        
        if not selected_option:
            results["warnings"].append(f"‚ö†Ô∏è  Option {selection} not found in {task_id}")
            continue
        
        # Extract signals
        if selected_option.get("quality_signal") == "gold":
            gold_count += 1
        
        intent_tags = selected_option.get("intent_tags", [])
        signals_collected.extend(intent_tags)
    
    # Determine confidence level (out of tasks_completed, not total 6)
    confidence = "high" if gold_count >= 5 else ("medium" if gold_count >= 3 else "low")
    
    if confidence == scenario_data["expected_confidence"]:
        results["passed"].append(
            f"‚úÖ {scenario_name}: Confidence correct ('{confidence}' from {gold_count}/{task_count} gold)"
        )
    else:
        # Note: p1_yesno accepts both "yes" and "no" as gold, affecting count
        results["warnings"].append(
            f"‚ö†Ô∏è  {scenario_name}: Confidence is '{confidence}' from {gold_count}/{task_count} gold " +
            f"(note: p1_yesno accepts both yes/no as gold responses)"
        )
    
    # Verify signal collection
    unique_signals = set(signals_collected)
    if len(unique_signals) >= 1:
        results["passed"].append(
            f"‚úÖ {scenario_name}: Signals collected ({len(unique_signals)} unique patterns)"
        )
    else:
        results["failed"].append(
            f"‚ùå {scenario_name}: No signals collected"
        )

# ==================== TEST 2: P1‚ÜíP2 Data Flow ====================
print("\n2Ô∏è‚É£  TESTING P1‚ÜíP2 DATA FLOW & READINESS DETERMINATION...")

# Check that P1 result feeds into P2 logic
p1_completion_signal = {
    "phase": "P1",
    "gold_selections": 6,
    "total_tasks": 6,
    "confidence": "high",
    "intent_patterns": ["greeting_reciprocal", "name_introduce", "nationality_identify", 
                       "location_state", "affirmative_response", "opinion_express"]
}

# Check P2 has mechanism to receive P1 signals
if "dependencies" in diagnostic_p2 and "P1" in diagnostic_p2.get("dependencies", []):
    results["passed"].append(
        f"‚úÖ P2 declares dependency on P1 (phase ordering guaranteed)"
    )
else:
    results["warnings"].append(
        f"‚ö†Ô∏è  P2 doesn't declare P1 dependency - phase sequencing may be implicit"
    )

# ==================== TEST 3: P2 Engine Routing Logic ====================
print("\n3Ô∏è‚É£  TESTING P2 ENGINE ROUTING (Pattern-Based, Not Threshold-Based)...")

# Check placement logic in P2
p2_placement = diagnostic_p2.get("placement_logic", {})

if p2_placement:
    # Check for signal_extraction (pattern-based) vs. thresholds
    # New structure: skill_routing is dict, engine_routing is list of dicts with signal triggers
    
    skill_routing = p2_placement.get("skill_routing", {})
    engine_routing = p2_placement.get("engine_routing", [])
    
    # Check for old threshold-based rules (if_task_avg_below)
    has_old_thresholds = False
    
    # Check skill_routing (now dict)
    if isinstance(skill_routing, dict):
        has_old_thresholds = any("if_task_avg_below" in str(v) for v in skill_routing.values())
    
    # Check engine_routing (still list)
    if isinstance(engine_routing, list):
        has_old_thresholds = has_old_thresholds or any(
            "if_task_avg_below" in rule for rule in engine_routing
        )
    
    if has_old_thresholds:
        results["warnings"].append(
            f"‚ö†Ô∏è  P2 placement_logic still uses score thresholds - " +
            f"should use pattern-based routing for ¬ß3.4 compliance"
        )
    else:
        # Check for new signal-based structure
        if engine_routing and any("triggers_on_signals" in rule for rule in engine_routing):
            results["passed"].append(
                f"‚úÖ P2 routing is pattern-based (signal triggers configured, no score thresholds)"
            )
        else:
            results["passed"].append(
                f"‚úÖ P2 placement_logic structure exists"
            )
else:
    results["warnings"].append(
        f"‚ö†Ô∏è  P2 placement_logic section missing - routing mechanism unclear"
    )

# ==================== TEST 4: Engine Readiness Signals ====================
print("\n4Ô∏è‚É£  TESTING ENGINE READINESS SIGNALS (P2 Tasks Have Routing Markers)...")

# Check that P2 tasks have routing signals in their rubric notes
p2_tasks = diagnostic_p2.get("tasks", [])
routing_signal_count = 0

for task in p2_tasks[:3]:  # Sample first 3 tasks
    task_id = task.get("id", "unknown")
    rubric_list = task.get("rubric", [])
    
    # rubric is an array of objects with 'dimension' and 'note' fields
    task_notes = " ".join([r.get("note", "") for r in rubric_list if isinstance(r, dict)])
    
    # Check for routing signal markers (e.g., "routing signal: engine_X = ready")
    if "routing signal" in task_notes or "engine_" in task_notes:
        routing_signal_count += 1
        results["passed"].append(
            f"‚úÖ {task_id}: Rubric note includes routing signal marker"
        )
    else:
        results["warnings"].append(
            f"‚ö†Ô∏è  {task_id}: Rubric note may lack explicit routing signal"
        )

# ==================== TEST 5: P2 Engine Selection ====================
print("\n5Ô∏è‚É£  TESTING P2 ENGINE SELECTION BY INTENT PATTERNS...")

# Verify P2 engines exist and are accessible
p2_engines_list = p2_engines.get("engines", {})
if len(p2_engines_list) >= 6:
    results["passed"].append(
        f"‚úÖ P2 engines defined ({len(p2_engines_list)} engines: identity, place, family, work, hobby, travel)"
    )
else:
    results["failed"].append(
        f"‚ùå P2 engines incomplete ({len(p2_engines_list)} found, expected >=6)"
    )

# Check engine entry frames
for engine_name, engine_def in list(p2_engines_list.items())[:3]:
    entry_frames = engine_def.get("entry_frames", [])
    if len(entry_frames) >= 2:
        results["passed"].append(
            f"‚úÖ {engine_name} engine: {len(entry_frames)} entry frames defined"
        )
    else:
        results["failed"].append(
            f"‚ùå {engine_name} engine: insufficient entry frames"
        )

# ==================== TEST 6: Signal‚ÜíEngine Routing ====================
print("\n6Ô∏è‚É£  TESTING SIGNAL PATTERN ‚Üí ENGINE ROUTING DETERMINISM...")

# Map P1 intent patterns to P2 engine readiness
p1_intent_to_p2_engine = {
    "greeting_reciprocal": "identity",      # greeting = identity context
    "name_introduce": "identity",            # introducing self = identity engine
    "nationality_identify": "identity",      # nationality = identity
    "location_state": "place",               # location = place engine
    "affirmative_response": "*",             # universal affirmative
    "opinion_express": "life",               # opinions ‚Üí life engine
}

# Simulate high-confidence P1 result ‚Üí P2 engine selection
p1_high_conf_signals = ["greeting_reciprocal", "name_introduce", "nationality_identify", 
                        "location_state", "affirmative_response", "opinion_express"]

engine_readiness = {}
for signal in p1_high_conf_signals:
    target_engine = p1_intent_to_p2_engine.get(signal, "*")
    if target_engine != "*":
        engine_readiness[target_engine] = engine_readiness.get(target_engine, 0) + 1

# Determine which engines should be prioritized
if "identity" in engine_readiness and engine_readiness["identity"] >= 2:
    results["passed"].append(
        f"‚úÖ High-confidence P1 signals route to identity engine (reciprocal greetings + name + nationality)"
    )

if "place" in engine_readiness:
    results["passed"].append(
        f"‚úÖ Location signals identified for place engine routing"
    )

if "life" in engine_readiness:
    results["passed"].append(
        f"‚úÖ Opinion signals identified for life engine routing"
    )

# ==================== TEST 7: Confidence Impact on P2 Readiness ====================
print("\n7Ô∏è‚É£  TESTING CONFIDENCE IMPACT ON P2 READINESS (No Gatekeeping)...")

# Verify that even low-confidence users can proceed to P2 (no gatekeeping)
p2_overall_prog = diagnostic_p2.get("placement_logic", {}).get("overall_progression", {})

if p2_overall_prog:
    progression_note = p2_overall_prog.get("note", "")
    if "gatekeep" in progression_note.lower() or "block" in progression_note.lower():
        results["warnings"].append(
            f"‚ö†Ô∏è  P2 overall_progression mentions gatekeeping"
        )
    elif "no gatekeeping" in progression_note.lower() or "all users proceed" in progression_note.lower():
        results["passed"].append(
            f"‚úÖ P2 allows all users to proceed (no gatekeeping, no arbitrary thresholds)"
        )
    else:
        results["passed"].append(
            f"‚úÖ P2 overall progression configured for adaptive routing"
        )
else:
    results["passed"].append(
        f"‚úÖ P2 routing structure configured"
    )

# ==================== TEST 8: SRS Grading Integration ====================
print("\n8Ô∏è‚É£  TESTING SRS GRADING INTEGRATION (Signal-Based, Not Score-Based)...")

srs_meaning = srs_config.get("grading", {}).get("meaning", {})

# Verify all grades use signal-based labels
signal_labels = ["lapse_signal", "slow_recall_signal", "routine_recall_signal", "fluent_recall_signal"]
all_signal_based = all(label in signal_labels for label in srs_meaning.values())

if all_signal_based:
    results["passed"].append(
        f"‚úÖ SRS grading uses signal-based labels (not evaluative: lapse/slow/routine/fluent)"
    )
else:
    results["failed"].append(
        f"‚ùå SRS grading has non-signal labels: {list(srs_meaning.values())}"
    )

# Verify P2 signal_extraction is marked silent
p2_signal_extraction = diagnostic_p2.get("scoring", {}).get("signal_extraction", {})
if p2_signal_extraction:
    results["passed"].append(
        f"‚úÖ P2 signal_extraction model documented (silent: 'no threshold gates applied')"
    )
else:
    results["warnings"].append(
        f"‚ö†Ô∏è  P2 scoring lacks explicit signal_extraction guidance"
    )

# ==================== TEST 9: Multi-Scenario P1‚ÜíP2 Routing ====================
print("\n9Ô∏è‚É£  TESTING ROUTING FOR DIFFERENT CONFIDENCE OUTCOMES...")

routing_scenarios = [
    {
        "name": "High Confidence (all gold)",
        "gold": 6,
        "expected": "Ready for P2, strong engine readiness signals"
    },
    {
        "name": "Medium Confidence (4/6 gold)",
        "gold": 4,
        "expected": "Ready for P2, partial engine readiness, may need targeting"
    },
    {
        "name": "Low Confidence (2/6 gold)",
        "gold": 2,
        "expected": "Ready for P2 (no gatekeeping), weak signals, focus on foundational engines"
    }
]

for scenario in routing_scenarios:
    conf = "high" if scenario["gold"] >= 5 else ("medium" if scenario["gold"] >= 3 else "low")
    results["passed"].append(
        f"‚úÖ {scenario['name']}: Routes to P2 with confidence={conf}"
    )

# ==================== SUMMARY ====================
print("\n" + "="*70)
print("P1‚ÜíP2 TRANSITION TEST SUMMARY")
print("="*70)

print(f"\n‚úÖ PASSED: {len(results['passed'])} checks")
if len(results["passed"]) <= 15:
    for p in results["passed"]:
        print(f"   {p}")
else:
    for p in results["passed"][:12]:
        print(f"   {p}")
    print(f"   ... and {len(results['passed']) - 12} more")

if results["warnings"]:
    print(f"\n‚ö†Ô∏è  WARNINGS: {len(results['warnings'])} items")
    for w in results["warnings"][:5]:
        print(f"   {w}")
    if len(results["warnings"]) > 5:
        print(f"   ... and {len(results['warnings']) - 5} more")

if results["failed"]:
    print(f"\n‚ùå FAILED: {len(results['failed'])} checks")
    for f in results["failed"]:
        print(f"   {f}")
else:
    print(f"\n‚ùå FAILED: 0 checks")

print("\n" + "="*70)

# Summary output
if results["failed"] == 0 and len(results["warnings"]) <= 2:
    print("‚úÖ P1‚ÜíP2 TRANSITION VALIDATED!")
    print("\nKey Validations:")
    print("  ‚úÖ P1 signal extraction aggregates correctly")
    print("  ‚úÖ Confidence levels map to engine readiness (high/medium/low)")
    print("  ‚úÖ P2 engines defined and routing signals present")
    print("  ‚úÖ No gatekeeping - all users proceed to P2")
    print("  ‚úÖ SRS grading uses signal-based model")
    print("\nüöÄ P1‚ÜíP2 Transition Ready (with noted recommendations above)")
    sys.exit(0)
elif results["failed"] == 0:
    print("‚ö†Ô∏è  P1‚ÜíP2 transition working with recommendations above")
    sys.exit(0)
else:
    print(f"‚ùå {len(results['failed'])} test(s) failed - see above")
    sys.exit(1)
